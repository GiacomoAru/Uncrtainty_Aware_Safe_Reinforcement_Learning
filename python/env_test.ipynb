{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c18488f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import time\n",
    "from datetime import timedelta\n",
    "from decimal import Decimal\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from mlagents_envs.base_env import ActionTuple\n",
    "from mlagents_envs.environment import UnityEnvironment\n",
    "\n",
    "from utils_policy_train import *\n",
    "from utils_testing import *\n",
    "from utils_uf_methods import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b6c0ac",
   "metadata": {},
   "source": [
    "# UF Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301bb7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UE methods\n",
    "uf_methods = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c72a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probabilistic Transition Model\n",
    "\n",
    "def prob_world_score(ray_obs, state_obs, \n",
    "                     action,\n",
    "                     prob_model, \n",
    "                     input_mean, input_std):\n",
    "    \n",
    "    # If no action is provided, return neutral score\n",
    "    if action is None:\n",
    "        return 0.0\n",
    "    \n",
    "    # Convert inputs to tensors\n",
    "    ray_obs = torch.tensor(ray_obs)\n",
    "    state_obs = torch.tensor(state_obs)\n",
    "    action = torch.tensor(action)\n",
    "    \n",
    "    # Concatenate all observations and action into a single vector\n",
    "    obs_concat = torch.cat([ray_obs.flatten(), state_obs, action]).unsqueeze(0)\n",
    "    \n",
    "    # Select only the relevant input features (ray stacks, state subset, last 2 features)\n",
    "    x = torch.cat([obs_concat[:, 17:17*4], \n",
    "                   obs_concat[:, 17*4 + 7: 17*4 + 7*4], \n",
    "                   obs_concat[:, -2:]], dim=1)\n",
    "    \n",
    "    # Normalize input with training statistics\n",
    "    x = (x - input_mean) / input_std\n",
    "    \n",
    "    # Forward pass: extract predictive variance only (no gradient)\n",
    "    with torch.no_grad():\n",
    "        _, var = prob_model(x)\n",
    "    var = var[0].sum().detach()\n",
    "    \n",
    "    # Return scalar uncertainty score\n",
    "    return float(var)\n",
    "\n",
    "\n",
    "# Load pre-trained probabilistic world model\n",
    "prob_method = torch.load('./u_e_test/prob_world_method.pth', weights_only=False)\n",
    "prob_world = ProbabilisticWorldModel(**prob_method['model_args'])\n",
    "prob_world.load_state_dict(prob_method['model_parameters'])\n",
    "prob_world.eval()\n",
    "\n",
    "# Register probabilistic world model method inside UF methods\n",
    "uf_methods['prob_world_model'] = lambda ray_obs, state_obs, action: prob_world_score(\n",
    "    ray_obs, state_obs, action, \n",
    "    prob_world,\n",
    "    prob_method['input_mean'], prob_method['input_std']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e31714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monte Carlo Dropout World Model\n",
    "\n",
    "def mcd_world_score(ray_obs, state_obs, \n",
    "                    action,\n",
    "                    mcd_model, \n",
    "                    input_mean, input_std):\n",
    "    \n",
    "    # If no action is provided, return neutral score\n",
    "    if action is None:\n",
    "        return 0.0\n",
    "    \n",
    "    # Convert inputs to tensors\n",
    "    ray_obs = torch.tensor(ray_obs)\n",
    "    state_obs = torch.tensor(state_obs)\n",
    "    action = torch.tensor(action)\n",
    "    \n",
    "    # Concatenate observations and action into a single vector\n",
    "    obs_concat = torch.cat([ray_obs.flatten(), state_obs, action]).unsqueeze(0)\n",
    "    \n",
    "    # Select the relevant subset of features (ray stacks, part of state, last 2 dims)\n",
    "    x = torch.cat([obs_concat[:, 17:17*4], \n",
    "                   obs_concat[:, 17*4 + 7: 17*4 + 7*4], \n",
    "                   obs_concat[:, -2:]], dim=1)\n",
    "    \n",
    "    # Normalize input with training statistics\n",
    "    x = (x - input_mean) / input_std\n",
    "    \n",
    "    # Forward pass with MC Dropout: compute variance across n_samples stochastic runs\n",
    "    with torch.no_grad():\n",
    "        _, var, _ = mcd_model.predict(x, n_samples=20)\n",
    "    var = var[0].sum().detach()\n",
    "    \n",
    "    # Return scalar uncertainty score\n",
    "    return float(var)\n",
    "\n",
    "\n",
    "# Load pre-trained Monte Carlo Dropout world model\n",
    "mcd_method = torch.load('./u_e_test/mcd_world_method.pth', weights_only=False)\n",
    "mcd_world = MCDropoutWorldModel(**mcd_method['model_args'])\n",
    "mcd_world.load_state_dict(mcd_method['model_parameters'])\n",
    "mcd_world.eval()\n",
    "\n",
    "# Register MCD world model method inside UF methods\n",
    "uf_methods['mcd_world_model'] = lambda ray_obs, state_obs, action: mcd_world_score(\n",
    "    ray_obs, state_obs, action,\n",
    "    mcd_world,\n",
    "    mcd_method['input_mean'], mcd_method['input_std']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d905672b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q-network Ensemble\n",
    "\n",
    "def qnet_ensemble_score(ray_obs, state_obs, \n",
    "                        action,\n",
    "                        qnet_ens):\n",
    "\n",
    "    # Convert inputs to tensors and add batch dimension\n",
    "    ray_obs = torch.tensor([ray_obs])\n",
    "    state_obs = torch.tensor([state_obs])\n",
    "    action = torch.tensor([action])\n",
    "    \n",
    "    with torch.no_grad():                                          \n",
    "        # Compute Q-values for each model in the ensemble\n",
    "        q_vals = torch.stack([\n",
    "            q(ray_obs, state_obs, action) for q in qnet_ens\n",
    "        ]) \n",
    "\n",
    "    # Compute variance across ensemble predictions (disagreement = uncertainty)\n",
    "    var = torch.var(q_vals.flatten()).detach()\n",
    "    return float(var)\n",
    "\n",
    "\n",
    "# Load pre-trained Q-network ensemble (5 members)\n",
    "qnet_method = torch.load('./u_e_test/qnet_method.pth', weights_only=False)\n",
    "qnet_ensemble = [DenseSoftQNetwork(**qnet_method['model_args']) for _ in range(5)]\n",
    "\n",
    "# Load parameters for each ensemble member\n",
    "for i, q in enumerate(qnet_ensemble):\n",
    "    q.load_state_dict(qnet_method['model_parameters'][i])\n",
    "\n",
    "# Set all networks to evaluation mode\n",
    "for q in qnet_ensemble:\n",
    "    q.eval()\n",
    "\n",
    "# Register Q-ensemble method inside UF methods\n",
    "uf_methods['qnet_ensemble'] = lambda ray_obs, state_obs, action: qnet_ensemble_score(\n",
    "    ray_obs, state_obs, action,\n",
    "    qnet_ensemble\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02355563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Network Distillation\n",
    "\n",
    "def rnd_score(ray_obs, state_obs, \n",
    "              action,\n",
    "              source_model, predictor_model, \n",
    "              input_mean, input_std):\n",
    "    \n",
    "    # Convert inputs to tensors and flatten ray observations\n",
    "    ray_obs = torch.tensor(ray_obs, dtype=torch.float32).flatten()\n",
    "    state_obs = torch.tensor(state_obs, dtype=torch.float32)\n",
    "    x = torch.cat([ray_obs, state_obs]).unsqueeze(0)\n",
    "\n",
    "    # Normalize with training statistics\n",
    "    x = (x - input_mean) / input_std\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Predictor tries to match the fixed random source\n",
    "        pred = predictor_model(x)\n",
    "        target = source_model(x)\n",
    "    \n",
    "    # Compute squared error (MSE) as novelty signal\n",
    "    diff = (pred - target) ** 2\n",
    "    diff = diff[0].sum() * 100  # scaled score\n",
    "    \n",
    "    # Return scalar uncertainty score\n",
    "    return float(diff)\n",
    "\n",
    "\n",
    "# Load pre-trained RND models (source and predictor networks)\n",
    "rnd_method = torch.load('./u_e_test/rnd_method.pth', weights_only=False)\n",
    "rnd_source = RNDNetwork(**rnd_method['model_args'])\n",
    "rnd_predictor = RNDNetwork(**rnd_method['model_args'])\n",
    "\n",
    "# Load parameters for both networks\n",
    "rnd_source.load_state_dict(rnd_method['model_parameters'][0])\n",
    "rnd_predictor.load_state_dict(rnd_method['model_parameters'][1])\n",
    "\n",
    "# Set models to evaluation mode\n",
    "rnd_source.eval()\n",
    "rnd_predictor.eval()\n",
    "\n",
    "# Register RND method inside UF methods\n",
    "uf_methods['rnd'] = lambda ray_obs, state_obs, action: rnd_score(\n",
    "    ray_obs, state_obs, action,\n",
    "    rnd_source, rnd_predictor,\n",
    "    rnd_method['input_mean'], rnd_method['input_std']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b6e2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random baseline\n",
    "def random_score(ray_obs, state_obs, action):\n",
    "    return random.randint(0, 100)\n",
    "\n",
    "\n",
    "# Register random baseline method inside UF methods\n",
    "uf_methods['random'] = random_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b82f6dad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1.0, 0.0043255239725112915),\n",
       " (10.0, 0.016104964539408684),\n",
       " (20.0, 0.026210537180304527),\n",
       " (30.0, 0.03698762133717537),\n",
       " (40.0, 0.0494244359433651),\n",
       " (50.0, 0.06499352306127548),\n",
       " (60.0, 0.08575601130723953),\n",
       " (65.0, 0.09925977140665054),\n",
       " (70.0, 0.11619290709495544),\n",
       " (75.0, 0.13798460364341736),\n",
       " (80.0, 0.1697603464126587),\n",
       " (85.0, 0.21788763999938965),\n",
       " (90.0, 0.32117959856987),\n",
       " (95.0, 0.6011334657669067),\n",
       " (99.0, 1.9817389249801636)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qnet_method['percentiles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a32ac32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1.0, 0.26237156987190247),\n",
       " (10.0, 0.36038389801979065),\n",
       " (20.0, 0.43789416551589966),\n",
       " (30.0, 0.5111830234527588),\n",
       " (40.0, 0.5836204290390015),\n",
       " (50.0, 0.6581688523292542),\n",
       " (60.0, 0.7393625974655151),\n",
       " (65.0, 0.7873311638832092),\n",
       " (70.0, 0.8432287573814392),\n",
       " (75.0, 0.9085058569908142),\n",
       " (80.0, 0.9850521087646484),\n",
       " (85.0, 1.091325044631958),\n",
       " (90.0, 1.2421854734420776),\n",
       " (95.0, 1.5098358392715454),\n",
       " (99.0, 2.2583086490631104)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcd_method['percentiles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2053588f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1.0, 0.13611337542533875),\n",
       " (10.0, 0.24117809534072876),\n",
       " (20.0, 0.32548123598098755),\n",
       " (30.0, 0.40168583393096924),\n",
       " (40.0, 0.4800463616847992),\n",
       " (50.0, 0.5671817660331726),\n",
       " (60.0, 0.6673864722251892),\n",
       " (65.0, 0.7246496677398682),\n",
       " (70.0, 0.791548490524292),\n",
       " (75.0, 0.8710367679595947),\n",
       " (80.0, 0.9697459936141968),\n",
       " (85.0, 1.1040456295013428),\n",
       " (90.0, 1.3025723695755005),\n",
       " (95.0, 1.670838475227356),\n",
       " (99.0, 2.764556884765625)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_method['percentiles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32d5e196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1.0, 0.07047063857316971),\n",
       " (10.0, 0.3038383424282074),\n",
       " (20.0, 0.5405747294425964),\n",
       " (30.0, 0.7670212388038635),\n",
       " (40.0, 1.011854648590088),\n",
       " (50.0, 1.281114935874939),\n",
       " (60.0, 1.6087371110916138),\n",
       " (65.0, 1.818676471710205),\n",
       " (70.0, 2.0656540393829346),\n",
       " (75.0, 2.4065101146698),\n",
       " (80.0, 2.8838393688201904),\n",
       " (85.0, 3.568255662918091),\n",
       " (90.0, 4.703351020812988),\n",
       " (95.0, 7.431720733642578),\n",
       " (99.0, 15.704105377197266)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_method['percentiles']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5a11d9",
   "metadata": {},
   "source": [
    "# Testing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6bcbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(CONFIG_DICT, \n",
    "         env, env_info, env_debug,\n",
    "         filter_methods, \n",
    "         actor, device):\n",
    "    \n",
    "    # Precompute ray angles for CBF checks\n",
    "    angoli_radianti_precalcolati = generate_angles_rad(\n",
    "        env_info.settings['ray_sensor_settings']['rays_per_direction'],\n",
    "        env_info.settings['ray_sensor_settings']['max_ray_degrees']\n",
    "    )\n",
    "\n",
    "    current_episode = 1\n",
    "    cumulative_obs = {}          # per-agent memory (obs, action, uncertainty info)\n",
    "    running_episodes = {}        # active episodes data\n",
    "    terminated_episodes = []     # finished episodes\n",
    "    stats = []                   # episode statistics\n",
    "    dataset = []                 # collected dataset\n",
    "        \n",
    "    while current_episode <= CONFIG_DICT['tot_episodes']:\n",
    "\n",
    "        env.step()\n",
    "        obs = collect_data_after_step(env, env_info)\n",
    "        \n",
    "        for id in obs:\n",
    "            agent_obs = obs[id]\n",
    "\n",
    "            # Handle terminated agents\n",
    "            if agent_obs[4] == 1:\n",
    "                if id in cumulative_obs:\n",
    "                    # Remove agent from active lists and finalize episode\n",
    "                    del cumulative_obs[id]\n",
    "                    terminated_episodes.append(running_episodes[id])\n",
    "                    del running_episodes[id]\n",
    "                else:\n",
    "                    # Agent killed very early\n",
    "                    terminated_episodes.append([])\n",
    "                    assert id not in running_episodes and id not in cumulative_obs\n",
    "                    \n",
    "            else:\n",
    "                actual_ray_obs = agent_obs[0]\n",
    "                actual_state_obs = agent_obs[1]\n",
    "                    \n",
    "                # Initialize new agent entry\n",
    "                if id not in cumulative_obs:\n",
    "                    cumulative_obs[id] = [\n",
    "                        CONFIG_DICT['decision_frame_period'], # steps until next decision\n",
    "                        None,   # last ray obs\n",
    "                        None,   # last state obs\n",
    "                        None,   # last action taken\n",
    "                        0.0,    # last uncertainty estimate\n",
    "                        True,   # last UF activation\n",
    "                    ]\n",
    "                    \n",
    "                # Time to decide an action\n",
    "                if cumulative_obs[id][0] >= CONFIG_DICT['decision_frame_period']:\n",
    "                    cumulative_obs[id][0] = 0\n",
    "                    \n",
    "                    # Update ray observations with frame stacking\n",
    "                    if cumulative_obs[id][1] is None:\n",
    "                        cumulative_obs[id][1] = actual_ray_obs\n",
    "                        cumulative_ray_obs = actual_ray_obs\n",
    "                    else:\n",
    "                        cumulative_ray_obs = cumulative_obs[id][1][1:, :] \n",
    "                        cumulative_ray_obs = np.concatenate([cumulative_ray_obs, actual_ray_obs[-1:, :]])\n",
    "\n",
    "                    # Update state observations with temporal stacking\n",
    "                    if cumulative_obs[id][2] is None:\n",
    "                        cumulative_obs[id][2] = actual_state_obs\n",
    "                        cumulative_state_obs = actual_state_obs\n",
    "                    else:\n",
    "                        cumulative_state_obs = cumulative_obs[id][2][env_info.settings['behavior_parameters_settings']['observation_size']:] \n",
    "                        cumulative_state_obs = np.concatenate([cumulative_state_obs, actual_state_obs[-env_info.settings['behavior_parameters_settings']['observation_size']:]])\n",
    "                    \n",
    "                    # Policy action from actor\n",
    "                    action, _, _, _ = actor.get_action(\n",
    "                        torch.Tensor([cumulative_ray_obs]).to(device), \n",
    "                        torch.Tensor([cumulative_state_obs]).to(device),\n",
    "                        CONFIG_DICT['var_scale']\n",
    "                    )\n",
    "                    action = action[0].detach().cpu().numpy()\n",
    "                    \n",
    "                    # Uncertainty filter (optional)\n",
    "                    if CONFIG_DICT['uncertainty_filter']['enabled']: \n",
    "                        uncertanty_estimate = filter_methods[CONFIG_DICT['uncertainty_filter']['method']](\n",
    "                            cumulative_ray_obs, \n",
    "                            cumulative_state_obs, \n",
    "                            action\n",
    "                        )\n",
    "                        cumulative_obs[id][4] = uncertanty_estimate\n",
    "                        cumulative_obs[id][5] = uncertanty_estimate > CONFIG_DICT['uncertainty_filter']['threshold']\n",
    "                    \n",
    "                    # Update agent memory\n",
    "                    cumulative_obs[id][1] = cumulative_ray_obs\n",
    "                    cumulative_obs[id][2] = cumulative_state_obs\n",
    "                    cumulative_obs[id][3] = action\n",
    "                    \n",
    "                    # Start new episode if not already tracked\n",
    "                    if id not in running_episodes:\n",
    "                        running_episodes[id] = []\n",
    "                    running_episodes[id].append({\n",
    "                        'ray': cumulative_ray_obs,\n",
    "                        'state': cumulative_state_obs,\n",
    "                        'u_e': cumulative_obs[id][4],\n",
    "                        'uf_activation': cumulative_obs[id][5],\n",
    "                        'action': action,\n",
    "                        'inner_steps': []\n",
    "                    })\n",
    "\n",
    "                # Use last predicted action by default\n",
    "                policy_action = cumulative_obs[id][3] \n",
    "                \n",
    "                # Control Barrier Function (CBF) correction\n",
    "                cbf_action = np.zeros(2)\n",
    "                if CONFIG_DICT['cbf']['enabled']:\n",
    "                    cbf_action = CBF_from_obs(\n",
    "                        actual_ray_obs[-1], policy_action, env_info,\n",
    "                        CONFIG_DICT['cbf']['d_safe'],\n",
    "                        CONFIG_DICT['cbf']['alpha'],\n",
    "                        CONFIG_DICT['cbf']['d_safe_mul'],\n",
    "                        angoli_radianti_precalcolati\n",
    "                    )\n",
    "                    # Ensure minimum forward velocity\n",
    "                    if policy_action[0] > CONFIG_DICT['cbf']['min_forward']:\n",
    "                        cbf_action[0] = max(CONFIG_DICT['cbf']['min_forward'], cbf_action[0])\n",
    "                    else:\n",
    "                        cbf_action[0] = max(policy_action[0], cbf_action[0])\n",
    "                \n",
    "                # Check if CBF activated\n",
    "                cbf_activation = CONFIG_DICT['cbf']['enabled'] and np.linalg.norm(cbf_action - policy_action) > 0.0001\n",
    "                running_episodes[id][-1]['inner_steps'].append([np.linalg.norm(cbf_action - policy_action), cbf_activation])\n",
    "                \n",
    "                # Final action selection (UF + CBF logic)\n",
    "                final_action = policy_action\n",
    "                if cumulative_obs[id][5] and cbf_activation:\n",
    "                    final_action = cbf_action\n",
    "                \n",
    "                # Debug visualization (optional)\n",
    "                if CONFIG_DICT['send_debug_action']:\n",
    "                    env_debug.send_agent_action_debug(\n",
    "                        final_action[0], final_action[1],\n",
    "                        policy_action[0], policy_action[1], \n",
    "                        cbf_activation, \n",
    "                        cbf_action[0], cbf_action[1],\n",
    "                        cumulative_obs[id][5],\n",
    "                        CONFIG_DICT['uncertainty_filter']['threshold'],\n",
    "                        cumulative_obs[id][4]\n",
    "                    ) \n",
    "                                                          \n",
    "                # Apply final action to environment\n",
    "                a = ActionTuple(continuous=np.array([final_action]))\n",
    "                env.set_action_for_agent(\n",
    "                    env_info.settings['behavior_parameters_settings']['behavior_name'], id, a\n",
    "                )\n",
    "                \n",
    "                # Increment frame counter\n",
    "                cumulative_obs[id][0] += CONFIG_DICT['frame_per_step']\n",
    "        \n",
    "        # Handle finished episodes\n",
    "        if len(env_info.msg_queue) == len(terminated_episodes) and len(terminated_episodes) > 0:\n",
    "            if len(terminated_episodes) == 1:\n",
    "                t_msg = env_info.msg_queue.pop() \n",
    "                t_episode = terminated_episodes.pop()\n",
    "                \n",
    "                if not t_episode:\n",
    "                    print(current_episode, '- agent killed too early, step', t_msg['length'])\n",
    "                else:\n",
    "                    stats.append(extract_stats(t_episode, t_msg, CONFIG_DICT))\n",
    "                    \n",
    "                    if current_episode % CONFIG_DICT['print_interval'] == 0:\n",
    "                        print_stats_light(stats, CONFIG_DICT['tot_episodes'])\n",
    "                        \n",
    "                    current_episode += 1\n",
    "                    \n",
    "                    # Save data if required\n",
    "                    if CONFIG_DICT['accumulate_data']:\n",
    "                        dataset.append([\n",
    "                            list(element['ray'].flatten()) + list(element['state']) + list(element['action'])\n",
    "                            for element in t_episode\n",
    "                        ])\n",
    "                        \n",
    "            else: \n",
    "                # Too many overlapping terminations → reset\n",
    "                print(current_episode, '- sovrapposition, deleting', len(terminated_episodes), 'episodes')\n",
    "                terminated_episodes = []\n",
    "                env_info.msg_queue = []\n",
    "                \n",
    "        # Safety check: queue should not grow indefinitely\n",
    "        if len(env_info.msg_queue) > CONFIG_DICT['message_queue_len_error'] or len(terminated_episodes) > CONFIG_DICT['message_queue_len_error']:\n",
    "            print('ERRORE')\n",
    "            raise AssertionError('Unexpected queue growth')\n",
    "\n",
    "    return stats, dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3139444c",
   "metadata": {},
   "source": [
    "# Start Testing Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37721b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG DICT\n",
    "CONFIG_DICT = {\n",
    "\n",
    "    'test_name': 'Test',\n",
    "    \n",
    "    'send_debug_action': True,  # Solo 1 agente supportato\n",
    "    'accumulate_data': False,\n",
    "    'save_stats':False,\n",
    "    'print_interval':25,\n",
    "    \n",
    "    'message_queue_len_error':10,\n",
    "    'cuda': True,\n",
    "    'tot_episodes': 10000,\n",
    "    \n",
    "    'decision_frame_period': 5,\n",
    "    'frame_per_step': 1,\n",
    "    \n",
    "    'var_scale': 2,\n",
    "    \n",
    "    'cbf': {\n",
    "        'd_safe': 1.25, \n",
    "        'd_safe_mul': 2, \n",
    "        'alpha': 5, \n",
    "        'min_forward': 0.05, \n",
    "        'enabled':True\n",
    "    },\n",
    "    \n",
    "    'uncertainty_filter': {\n",
    "        'method': 'mcd_world_model',\n",
    "        'enabled': True,\n",
    "        'threshold': 0.9085058569908142\n",
    "    },\n",
    "}\n",
    "\n",
    "if CONFIG_DICT['decision_frame_period'] % CONFIG_DICT['frame_per_step'] != 0:\n",
    "    print(\"ATTENZIONE ESPLODERA' TUTTO!!\")\n",
    "CONFIG_DICT['run_name'] = 'base_2179199' # 'base+wp_2183943'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa50d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#TESTING DICT\n",
    "\n",
    "CONFIG_DICT = {\n",
    "    'test_name': 'base',\n",
    "    \n",
    "    'send_debug_action': False,  # Solo 1 agente supportato\n",
    "    'accumulate_data': False,\n",
    "    'save_stats': True,\n",
    "    'print_interval':25,    \n",
    "    'message_queue_len_error':10,\n",
    "    'cuda': True,\n",
    "\n",
    "    'tot_episodes': 1000,\n",
    "    \n",
    "    'decision_frame_period': 5,\n",
    "    'frame_per_step': 1,\n",
    "    \n",
    "    'var_scale': 0.9,\n",
    "    \n",
    "    \n",
    "    #'cbf': {'d_safe': 1.25, 'd_safe_mul': 2,  'alpha': 5, 'min_forward': 0.05, 'enabled':True},\n",
    "    \n",
    "    #'uncertainty_filter': {'method': 'mcd_world_model','enabled': True,'threshold': 0.8526}\n",
    "}\n",
    "\n",
    "if CONFIG_DICT['decision_frame_period'] % CONFIG_DICT['frame_per_step'] != 0:\n",
    "    print(\"ATTENZIONE ESPLODERA' TUTTO!!\")\n",
    "CONFIG_DICT['run_name'] = 'base_2179199' # 'base+wp_2183943'\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501778c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c558155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the channel\n",
    "env_info = CustomChannel()\n",
    "env_debug = DebugSideChannel()\n",
    "\n",
    "# env setup\n",
    "env = UnityEnvironment(None, seed=random.randint(-100000, 100000), side_channels=[env_info, env_debug])\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f595431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the saved models\n",
    "path = './new_models/' + CONFIG_DICT['run_name']\n",
    "\n",
    "actor = DenseActor((env_info.settings['ray_sensor_settings']['observation_stacks'],\n",
    "                    2*env_info.settings['ray_sensor_settings']['rays_per_direction'] + 1), \n",
    "                env_info.settings['behavior_parameters_settings']['observation_size']*env_info.settings['behavior_parameters_settings']['stacked_vector'], \n",
    "                env_info.settings['behavior_parameters_settings']['continuous_actions'], \n",
    "                env_info.settings['behavior_parameters_settings']['min_action'], \n",
    "                env_info.settings['behavior_parameters_settings']['max_action'], \n",
    "                [128,128,128]).to(device)\n",
    "actor.load_state_dict(torch.load(os.path.join(path, 'actor_best.pth')))\n",
    "actor.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04887a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cbf_conf = [{'d_safe': 0, 'd_safe_mul': 0, 'alpha': 0, 'min_forward': 0, 'enabled':False},\n",
    "            {'d_safe': 1.25, 'd_safe_mul': 2, 'alpha': 5, 'min_forward': 0.05, 'enabled':True}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c9a9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG RUN\n",
    "env_info.reset()\n",
    "env.reset()\n",
    "\n",
    "stats, dataset = test(CONFIG_DICT,\n",
    "                    env, env_info, env_debug,\n",
    "                    uf_methods,\n",
    "                    actor, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9d00c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# TESTING RUN\n",
    "\n",
    "start_from = 'SCW_rnd_20pctl_cbf1'\n",
    "start = True\n",
    "\n",
    "uf_thresh = [prob_method['percentiles'], mcd_method['percentiles'], qnet_method['percentiles'], rnd_method['percentiles'],\n",
    "             random_percentiles] \n",
    "uf_names = ['prob_world_model', 'mcd_world_model', 'qnet_ensemble', 'rnd','random']\n",
    "\n",
    "for j, cbf_c in enumerate(cbf_conf):\n",
    "    \n",
    "    if j != 1:\n",
    "        continue\n",
    "    \n",
    "    for i, uf_name in enumerate(uf_names):\n",
    "        \n",
    "        if i != 4:\n",
    "            continue\n",
    "        \n",
    "        save_dir = f'./results/MO_{uf_name}'\n",
    "        base_name = f'MO_{uf_name}'\n",
    "        unc_prob = []\n",
    "        percentuali = []\n",
    "        \n",
    "        for perc, val in uf_thresh[i]:\n",
    "            unc_prob.append({'method': uf_name, 'enabled': True, 'threshold': float(val)})\n",
    "            percentuali.append(perc)\n",
    "        \n",
    "        for i, unc_c in enumerate(unc_prob):\n",
    "            \n",
    "            CONFIG_DICT['test_name'] = f\"{base_name}_{int(percentuali[i])}pctl_cbf{j}\"\n",
    "            \n",
    "            CONFIG_DICT['uncertainty_filter'] = unc_c\n",
    "            CONFIG_DICT['cbf'] = cbf_c\n",
    "\n",
    "            print('Starting', CONFIG_DICT['test_name'], '--', CONFIG_DICT['uncertainty_filter']['threshold'])\n",
    "\n",
    "            if CONFIG_DICT['test_name'] == start_from:\n",
    "                start = True\n",
    "            if start:\n",
    "                \n",
    "                done = False\n",
    "                start_time = time.time()\n",
    "                while not done:\n",
    "                    env_info.reset()\n",
    "                    env.reset()\n",
    "                \n",
    "                    try:\n",
    "                        stats, dataset = test(CONFIG_DICT,\n",
    "                                            env, env_info, env_debug,\n",
    "                                            uf_methods,\n",
    "                                            actor, device)\n",
    "                        done = True\n",
    "                    except AssertionError:\n",
    "                        continue\n",
    "\n",
    "                duration = time.time() - start_time\n",
    "                duration_str = str(timedelta(seconds=duration))[:-3]\n",
    "                \n",
    "                if CONFIG_DICT['save_stats']:\n",
    "                    save_stats(stats, env_info.settings, CONFIG_DICT,\n",
    "                            CONFIG_DICT['test_name'] + f'_{int(time.time()) - 1751796000}',\n",
    "                            save_dir,\n",
    "                            duration=duration_str)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0705382e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataset to JSON if accumulation is enabled\n",
    "if CONFIG_DICT['accumulate_data']: \n",
    "    \n",
    "    # Recursive helper to convert all numbers into float (JSON safe)\n",
    "    def convert_all_to_float(obj):\n",
    "        if isinstance(obj, dict):\n",
    "            return {k: convert_all_to_float(v) for k, v in obj.items()}\n",
    "        elif isinstance(obj, (list, tuple)):\n",
    "            return [convert_all_to_float(item) for item in obj]\n",
    "        elif isinstance(obj, (np.floating, Decimal)):\n",
    "            return float(obj)\n",
    "        else:\n",
    "            return obj\n",
    "        \n",
    "    # Save dataset with timestamp in filename\n",
    "    with open(f'./results/test_{int(time.time()) - 1751796000}.json', 'w+') as file:\n",
    "        file.write(json.dumps(convert_all_to_float(dataset)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996c8b7d",
   "metadata": {},
   "source": [
    "# Close Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5d4909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# close the environment\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".newenv (3.10.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
